"""
EduCode Backend - AISolution Model

Defines the AISolution entity storing AI-generated reference solutions.
Each task gets 4 AI solutions: 3 from OpenAI, 1 from Anthropic.
"""

from datetime import datetime
from enum import Enum
from typing import Optional, Dict, Any
import json

from sqlalchemy import Column, Integer, String, Text, DateTime, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func

from app.core.database import Base


class AIProvider(str, Enum):
    """AI providers for solution generation."""
    OPENAI = "openai"
    ANTHROPIC = "anthropic"


class AISolution(Base):
    """
    AISolution model representing AI-generated reference solutions.
    
    For each task, the system generates 4 reference solutions:
    - 3 from OpenAI (different approaches)
    - 1 from Anthropic
    
    These solutions are used for similarity comparison with student submissions.
    
    Attributes:
        id: Primary key
        task_id: Foreign key to Task
        provider: AI provider (openai/anthropic)
        variant_index: Solution variant number (1-3 for OpenAI, 1 for Anthropic)
        code: The AI-generated code solution
        meta: JSON metadata (model, prompt, tokens, etc.)
        created_at: Timestamp when solution was generated
        updated_at: Timestamp when solution was last updated
    """
    
    __tablename__ = "ai_solutions"
    
    # Primary key
    id = Column(Integer, primary_key=True, index=True)
    
    # Foreign key
    task_id = Column(Integer, ForeignKey("tasks.id"), nullable=False, index=True)
    
    # AI solution information
    provider = Column(SQLEnum(AIProvider), nullable=False, index=True)
    variant_index = Column(Integer, nullable=False, index=True)
    code = Column(Text, nullable=False)
    meta = Column(Text, nullable=True)  # JSON string for metadata
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)
    
    # Relationships
    # FIXED: Use lazy="selectin" to prevent greenlet errors when accessing relationships in async context
    task = relationship("Task", back_populates="ai_solutions", lazy="selectin")
    
    def __repr__(self) -> str:
        return f"<AISolution(id={self.id}, task_id={self.task_id}, provider='{self.provider}', variant={self.variant_index})>"
    
    @property
    def meta_data(self) -> Dict[str, Any]:
        """Parse and return metadata as dictionary."""
        if not self.meta:
            return {}
        try:
            return json.loads(self.meta)
        except (json.JSONDecodeError, TypeError):
            return {}
    
    @meta_data.setter
    def meta_data(self, value: Dict[str, Any]) -> None:
        """Set metadata from dictionary."""
        self.meta = json.dumps(value) if value else None
    
    @property
    def code_length(self) -> int:
        """Get the length of the AI-generated code."""
        return len(self.code)
    
    @property
    def code_lines(self) -> int:
        """Get the number of lines in the AI-generated code."""
        return len(self.code.splitlines())
    
    @property
    def model_name(self) -> Optional[str]:
        """Get the AI model name from metadata."""
        return self.meta_data.get("model")
    
    @property
    def prompt_used(self) -> Optional[str]:
        """Get the prompt used to generate this solution."""
        return self.meta_data.get("prompt")
    
    @property
    def tokens_used(self) -> Optional[int]:
        """Get the number of tokens used for generation."""
        return self.meta_data.get("tokens")
    
    @property
    def is_openai_solution(self) -> bool:
        """Check if this solution was generated by OpenAI."""
        return self.provider == AIProvider.OPENAI
    
    @property
    def is_anthropic_solution(self) -> bool:
        """Check if this solution was generated by Anthropic."""
        return self.provider == AIProvider.ANTHROPIC